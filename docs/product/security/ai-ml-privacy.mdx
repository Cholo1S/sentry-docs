---
title: "AI/ML Privacy Policy"
sidebar_order: 10
description: "Learn about Sentry's AI/ML Privacy Policy"
---


Throughout Sentry’s history, we’ve operated under a policy of [privacy by default](https://blog.sentry.io/terms-of-service-update/?). This same principal applies to our work in the Artificial Intelligence (AI) and Machine Learning (ML) space, where we want to be just as [transparent](https://blog.sentry.io/terms-of-service-update/) about what data we’re using and why.

Sentry is at a juncture where data and experience quality is much harder to maintain using traditional heuristics-based approaches. For example, fingerprinting error events as part of creating groups, has gotten a lot more complicated with the rise of JavaScript, and the use of extensions and third-party services. To train and validate models for grouping, notifications, and issue priority, Sentry will now need access to additional service data in order to be able to deliver a better user experience.

## General Consent

Navigating to /settings/legal/, you’ll see a new option for “Service Data Consent.” The purpose of having access to this data is to improve Sentry’s ability to train internal models to better fingerprint errors and prioritize data within the Sentry system. While our model inputs will use customer data, the outputs will never risk exposing customer information.

We’re asking for access to the following forms of service data:

- Error message
- Stack trace
- Span
- DOM interactions

Our intended improvements will harness text embeddings – converting words into numerical values that capture their semantic information. In this context, we’ll treat embeddings as a set of features for a downstream task. For example, we may use this aggregated dataset to train a model that can predict the severity of a new issue. **The information within these embeddings cannot identify specific organizations, projects, or issues**. Moreover, our policy on GDPR deletion requests will apply to any data we leverage for AI features - if we are required to delete any sensitive data in our production database, we will also delete the corresponding numerical embedding from our vector database.

## Generative AI

A subset of upcoming features will use Generative AI and Retrieval Augmented Generation (RAG). In this context, we will use text embeddings as an index - a way to retrieve the most contextually relevant bits of source code (via our GitHub integration) or events for a particular Sentry issue. When it comes to RAG, embeddings will always be logically separated (never cross customer boundaries). We may use embeddings to provide improved context to our suggested fix feature, help with semantic search, or improve the relevance of the issue details page, but only for the specific customer whose service data those embeddings were derived. All functionality leveraging RAG will require user opt-in; if you do not intend to take advantage of these features, nothing will change.

## Data Handling

In addition to the consent mechanisms mentioned above:

1. We will continue to encourage all our customers to use our [various data scrubbing tools](https://docs.sentry.io/product/data-management-settings/scrubbing/) so that service data is sanitized before we receive it.
2. We will apply the same deletion and retention rules to our training data as we do to the underlying service data. This means that if you delete service data, it will also be removed from our machine learning models automatically.
3. We will scrub data for PII before it goes into any training set.
4. We will ensure that the only service data presented in the output of any ML feature belongs to the customer using the feature.
5. We will only use AI models built in-house or provided by our existing trusted [third-party sub-processors](https://sentry.io/legal/subprocessors/) who have made contractual commitments that are consistent with the above.

We are confident that with these controls in place, we will be able to use service data and usage data to improve our products through AI while still protecting that very data.
